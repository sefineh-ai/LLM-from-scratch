# LLM-from-scratch

[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-blue?logo=pytorch)](https://pytorch.org/) [![Modular Code](https://img.shields.io/badge/Modular%20Code-Yes-brightgreen)](./) [![License: Public Domain](https://img.shields.io/badge/license-Public%20Domain-brightgreen.svg)](https://www.gutenberg.org/policy/license.html)

> **A modular, professional, and educational implementation of a GPT-style next-token generator in PyTorch.**

---

## üöÄ Project Overview

**LLM-from-scratch** is a clean, modular, and extensible implementation of a GPT-style character-level language model. Designed for both learning and rapid prototyping, this project demonstrates modern ML engineering best practices, including:

- Clear separation of model, tokenizer, training, and inference logic
- Readable, well-documented code
- Easy extensibility for research and production prototyping
- Minimal dependencies (just PyTorch)

---

## üèóÔ∏è Project Structure

```
LLM-from-scratch/
‚îú‚îÄ‚îÄ model.py        # Model classes (GPT, TransformerBlock, etc.)
‚îú‚îÄ‚îÄ tokenizer.py    # CharTokenizer and tokenization utilities
‚îú‚îÄ‚îÄ train.py        # Training loop and batch generation
‚îú‚îÄ‚îÄ chat.py         # Chat/interactive generation logic
‚îú‚îÄ‚îÄ main.py         # Entry point: loads data, trains, and launches chat
‚îú‚îÄ‚îÄ sample_chat_corpus.txt  # Training data (default: Alice in Wonderland)
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

---

## üß© Architecture Diagram

```mermaid
graph TD;
    A[main.py] --> B[model.py];
    A --> C[tokenizer.py];
    A --> D[train.py];
    A --> E[chat.py];
    D --> B;
    D --> C;
    E --> B;
    E --> C;
```

---

## ‚ú® Features
- **Modern Transformer Architecture:** Multi-head causal self-attention, position-wise feedforward, custom LayerNorm
- **Character-level Tokenization:** No external dependencies
- **Next-token Generation:** Auto-regressive, temperature and top-k sampling
- **Interactive Chat:** CLI-based, easy to extend to web or API
- **Extensible & Readable:** Perfect for research, education, and prototyping

---

## üìö Dataset
- Default: [Alice's Adventures in Wonderland](https://www.gutenberg.org/ebooks/11) (Project Gutenberg, public domain)
- Swap in any plain text file by replacing `sample_chat_corpus.txt`

---

## ‚ö° Quickstart

1. **Clone the repository:**
   ```bash
   git clone https://github.com/sefineh-ai/LLM-from-scratch.git
   cd LLM-from-scratch
   ```
2. **(Optional) Create and activate a virtual environment:**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```
3. **Install dependencies:**
   ```bash
   pip install torch
   ```
4. **(Optional) Replace `sample_chat_corpus.txt` with your own text.**
5. **Train and chat:**
   ```bash
   python3 main.py
   ```

---

## üõ†Ô∏è Extensibility
- **Swap in your own tokenizer** (word-level, BPE, etc.) via `tokenizer.py`
- **Upgrade the model** (add layers, attention types, etc.) in `model.py`
- **Integrate with web or API** by extending `chat.py`
- **Experiment with datasets** by changing `sample_chat_corpus.txt`
- **Add logging, callbacks, or experiment tracking** as needed

---

## üìù Example Output
```
You: The rabbit
AI:  was running very fast and Alice followed him down the hole.
```

---

## ü§ù Contributing
We welcome contributions, issues, and feature requests! Please open an issue or submit a pull request.

---

## üìÑ License & Credits
- **Code:** MIT License or Public Domain (choose your preferred open license)
- **Dataset:** [Project Gutenberg, Alice's Adventures in Wonderland](https://www.gutenberg.org/ebooks/11) (public domain)

---

**Created and maintained by [Your Name or GitHub handle]** 